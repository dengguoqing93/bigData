#### 第2次课后作业——Hadoop源码二次开发模块<br/>

##### 1. Kafka数据积压如何处理？

+ 增加Kafka集群的节点，进行集群扩容

+ 增加有数据积压的topic的partition分区数,同时增加消费者

+ 增加消费的线程数量

##### 2. Kafka的分区为什么没有设计读写分离？

​			读写分离存在以下两个问题：

+ 数据一致性问题

+ 延时问题

  

  ​		读写分离可以实现一定的负载均衡，避免所有压力都在一个节点，而kafka的不同topic的分区的主节点在设计的时候已经不在同一台主机，可以实现一定的负载均衡，因此不需要进一步通过读写分离实现负载均衡。且在没有使用读写分离时，有如下优点：

+ 简化代码逻辑

+ 没有延时的影响

+ 在副本稳定的情况下，不会出现数据不一致的情况 

##### 3. Kafka为什么读写效率高

+ 读场景的高效率设计
  + 零拷贝的方式读取数据
  + 索引，以及跳表的设计
+ 写场景的高效设计
  + 顺序写的方式
  + 批量写处理的设计

##### 4. kafka中生产数据的时候，如何保证写入的容错性？

​		通过引入分区副本机制保证容错性，副本通过ISR同步副本为多个保证单个分区副本出问题后可以正常运行		

##### 5. 说说Kafka的ISR副本同步队列

​		 ISR(in-sync replica)就是kafka为某个分区维护的一组同步集合，即每个分区都有自己的一个ISR集合，处于IRS集合的副本，即follower副本与leader副本保持同步状态，只有处于ISR集合中的副本才资格被选举为leader。

​	   同步副本的条件：

+ 与Zookeeper之间有一个活跃的会话，即在过去的6s(可配置)内向zookeeper发送过心跳
+ 在过去的10s内从leader获取过消息

##### 6. 哪些场景你会选择Kafka？

+ 需要高吞吐的场景
+ 允许数据部分丢失或重复

##### 7.Kafka 分区的目的？

​		Kafka通过分区实现数据冗余和伸缩性，分区可以分布在不同的服务器上，即一个主题可以横跨多个分区，以此来提供比单个服务器更强大的性能

##### 8. Kafka 高效文件存储设计特点？

​		顺序读写磁盘

​		索引，跳表设计

##### 9.Kafka 是如何实现高吞吐率的？

​		批量发送消息

​		 顺序读写：Kafka将消息写入到分区partition中，分区中的消息是顺序读写的

​		 零拷贝：生产者、消费者对于kafka中的消息是采用零拷贝实现的

​		消息压缩：kafka允许对消息集合进行压缩

##### 10. 可以对Kafka 进行监控的工具，你知道的有哪些？

##### 11. Kafka 分区数可以增加或减少吗？说说你自己的理解？

​		可以增加不可以减少。

​		增加分区时,如果分区时根据key进行分区可能影响数据的有序性可以已经存在的数据使用对应的key无法查询到数据。

​		不支持减少分区，因为减少分区时，当前分区的数据不太好处理，如果直接删除会导致数据丢失，如果分配到其他分区，则原有分区数据如何保障有序性等问题。简而言之，删除分区时，该分区的数据不好处理，会导致程序的复杂性急剧上升。

##### 12. 比较RabbitMQ与Apache Kafka

##### 13. 说出三个Kafka 与传统消息系统之间的关键区别

##### 14. Kafka中的分区器、序列化器、拦截器是否了解？它们之间的处理顺序是什么？

​		分区器，是用来寻找消息存放在那个分区的，主要根据键来确认分区

​		序列化器：网络传输中，需要对要传输的数据进行序列化。

​		拦截器：消息发送前，对数据进行修饰处理

顺序：拦截器->序列化器->分区器

##### 15. Kafka服务器能接收到的最大信息是多少?

​		单条消息的默认最大值为1M,可以根据需要修改改参数

​		单个批次大小的默认最大值为32M,可以根据需要修改该参数

##### 16. kafka producer如何优化打入速度

​		1.增加processor线程数，默认值为3

​		2.增加handler线程数，默认为8

​		3.增加批量发送值的大小，使得单个批次发送的数据量更大

##### 17. 新增分区Spark 能发现吗

##### 18. 如果leader crash时，ISR为空怎么办?

​		如果unclean.leader.election.enable设置为true，即允许不同步的副本成为leader，那么就会从不同步的副本中选出出一个新的leader。这样会产生数据不一致问题

​		如果上述参数设置为false，则在leader恢复之前，该分区将会不可用

##### 19. 如何保证Kafka数据不丢？

+ producer端
  + ack的配置策略：将acks设置为-1或者all。则生产者会等待ISR中所有的副本都成功写入后，才返回响应
  + retries的配置策略：设置重试策略以及错误处理的策略
+ consumer端：
  + offset commit的配置：将offset commit设置为手动提交
+ broker端：
  + replication-factor：副本数，创建tiopic时的副本数，通常设置为3
  + min.insync.replicas ：分区ISR队里集合中最少有多少个副本，默认值为1
  + unclear.leader.election.enable：是否允许非同步副本提升为leader，默认设置为false，为保证数据不丢失，该值应该设置为false

##### 20. kafka数据重复的问题如何解决？

​		把kafka消费者的配置enable.auto.commit设置为false